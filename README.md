# ğŸ“ AdHocâ€‘LM
*A transformerâ€‘based language model built from scratch, specialized for diplomacy, resolutions, and debate (work in progress).*

---

## ğŸŒ Overview
**AdHocâ€‘LM** is my ongoing project to **build a large language model from scratch in PyTorch**.  

The longâ€‘term goal is to create a model specialized in **diplomatic communication, resolution drafting, and debate simulation**.  
Right now, the project is in **Phase 1: Core LLM Build**, where Iâ€™m implementing the fundamental transformer components and training a **Miniâ€‘AdHocâ€‘LM** on small datasets (e.g., Shakespeare, TinyStories, WikiText).  

This repo will be updated as I progress through each phase:  
1. Core LLM Build (now)  
2. Scaling & Engineering  
3. Domain Specialization  
4. Application & RAG Integration  
5. Visualization & Portfolio Polish  

---

## ğŸ”¹ Current Status (Phase 1)
- âœ… Repository initialized  
- âœ… Environment set up (PyTorch, CUDA, Hugging Face)  
- âœ… Tokenizer + embeddings implemented  
- ğŸš§ Working on: Multiâ€‘head attention module  

---

## ğŸ“Š Dataset (Phase 1)
- **Shakespeare text** (tiny, great for debugging)  
- **TinyStories dataset** (lightweight natural language corpus)  
- Later: WikiTextâ€‘103 & OpenWebText for scaling  

**Next Steps:**  
- Implement feedforward layers & normalization  
- Add causal masking for autoregressive training  
- Build training loop  
- Train **Miniâ€‘AdHocâ€‘LM** (5â€“10M parameters) on Shakespeare dataset  

---

## ğŸ—ï¸ Architecture (WIP)
Currently implementing a **decoderâ€‘only transformer** (GPTâ€‘style):  
- âœ… Token + positional embeddings  
- ğŸš§ Multiâ€‘head selfâ€‘attention  
- â³ Feedforward layers + normalization  
- â³ Causal masking  

---

## ğŸ§© Roadmap
- [x] Initialize repo + environment  
- [x] Implement tokenizer + embeddings  
- [ ] Multiâ€‘head attention  
- [ ] Training loop for Miniâ€‘AdHocâ€‘LM  
- [ ] Pretrain Miniâ€‘AdHocâ€‘LM on Shakespeare  
- [ ] Publish initial training curves  

---

## ğŸ™Œ Acknowledgements
- Sebastian Raschka â€” *â€œBuild a Large Language Model (From Scratch)â€*  
- Hugging Face community datasets  